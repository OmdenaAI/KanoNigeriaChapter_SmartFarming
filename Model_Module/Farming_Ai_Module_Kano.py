# -*- coding: utf-8 -*-
"""FARMING_AI_MODEL_KANO.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hzapO7oOy17oqYA7PtYM0ZzcYqyFrbcL
"""



# import Dependencies

import pandas as pd
import numpy as np
from pathlib import Path
import joblib
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error




def data_preprocess_precip(data_path, sub_reg=None):
  """Preprocesses precipitation data for a specific sub-region.

  Reads the data from a CSV file, filters by sub-region, calculates rolling averages,
  and splits the data into training and testing sets for model training.

  Args:
      data_path (str): The path to the CSV file containing the precipitation data.
      sub_reg (str, optional): The name of the sub-region to filter the data by.
                              Defaults to None (no filtering).

  Returns:
      tuple: A tuple containing the following elements:
          - X_train (pandas.DataFrame): The training features.
          - X_test (pandas.DataFrame): The testing features.
          - y_train (pandas.Series): The training target (precipitation).
          - y_test (pandas.Series): The testing target (precipitation).
  """
  # Read data
  df = pd.read_csv(data_path, index_col='date', parse_dates=True)
  # Filter my sub region
  reg_data = df[df['SUB_REGION'] == sub_reg]
  # Reset index columns
  data_df = reg_data.iloc[:, [4, 0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11]]
  # Rolling windows
  data_df_roll = data_df.rolling(window=10).mean()
  data_df_roll.dropna(inplace=True)
  # Set feature and target
  X = data_df_roll.iloc[:, 1:]
  y = data_df_roll['Precipitation (mm/day)']

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=False)

  return X_train, X_test, y_train, y_test


def data_preprocess_soil(data_path, sub_reg=None):
  """Preprocesses soil moisture data for a specific sub-region.

  Reads the data from a CSV file, filters by sub-region, calculates rolling averages,
  and splits the data into training and testing sets for model training.

  Args:
      data_path (str): The path to the CSV file containing the soil moisture data.
      sub_reg (str, optional): The name of the sub-region to filter the data by.
                              Defaults to None (no filtering).

  Returns:
      tuple: A tuple containing the following elements:
          - X_train (pandas.DataFrame): The training features.
          - X_test (pandas.DataFrame): The testing features.
          - y_train (pandas.Series): The training target (soil moisture).
          - y_test (pandas.Series): The testing target (soil moisture).
  """
  # Read data
  df = pd.read_csv(data_path, index_col='date', parse_dates=True)
  # Filter my LGA or Sub_region
  sub_reg_data = df[df['SUB_REGION'] == sub_reg]
  # Reset index columns
  data_df = sub_reg_data.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]
  # Rolling windows
  data_df_roll = data_df.rolling(window=10).mean()
  data_df_roll.dropna(inplace=True)
  # Set feature and target
  target_col = 'Profile_Soil_Moisture'
  feature_cols = ['Temperature_at_2-Meters (C)',
                  'Temperature_at_2_Meters_Maximum (C)',
                  'Temperature-at_2_Meters_Minimum (C)',
                  'Wind_Speed_at_2_Meters_Maximum (m/s)',
                  'Wind_Speed_at_2_Meters_Minimum (m/s)',
                  'Wind_Speed_at_2_Meters (m/s)',
                  'Wind_Direction_at_2_Meters (Degrees)',
                  'Precipitation (mm/day)']
  X = data_df_roll[feature_cols]
  y = data_df_roll[target_col]

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=False)

  return X_train, X_test, y_train, y_test


def train_model_precip(data_path, sub_reg=None):

  """
  Trains an XGBoost regression model to predict precipitation for a specific Local Government Area (LGA).

  This function preprocesses the data, performs hyperparameter tuning using RandomizedSearchCV,
  trains the model with the best hyperparameters, and saves the trained model to a file.

  Args:
      path (str): The file path to the historical weather data CSV file.
      lga (str): The Local Government Area (LGA) for which to train the model.
      output_path (str): The base file path for saving the trained model.
                        The LGA name will be appended to this path.

  Returns:
      xgboost.XGBRegressor: The trained XGBoost regression model.
"""

  from sklearn.model_selection import RandomizedSearchCV

  params = {
    "objective": ["reg:squarederror"],
    "eval_metric": [mean_squared_error],
    "learning_rate": [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],
    "max_depth": [4, 5, 6, 7, 8, 10, 12],
    "n_estimators": [50, 100, 200, 400, 500],
    "subsample": [0.6, 0.7, 0.8, 0.9, 1.0],
    "gamma": [0, 0.1, 0.2, 0.3, 0.4],
    "colsample_bytree": [0.3, 0.6, 0.7, 0.8]
    }

  X_train, _, y_train, _ = data_preprocess_precip(data_path, sub_reg=sub_reg)


  # Train the model

  model = xgb.XGBRegressor(**params)

  grid_search = RandomizedSearchCV(model, params, cv=5, scoring='r2', n_jobs=-1, verbose=5)
  grid_search.fit(X_train, y_train)

  best_model = xgb.XGBRegressor(**(grid_search.best_params_))
  best_model.fit(X_train, y_train)

  joblib.dump(best_model, f"precip_{sub_reg}.json", compress=8)

  return best_model



def train_model_soil(data_path, sub_reg=None):
  """Trains a RandomForestRegressor model to predict soil moisture.

  This function preprocesses soil moisture data for a specific sub-region,
  trains a RandomForestRegressor model using the training data,
  and saves the trained model to a file.

  Args:
      data_path (str): The path to the CSV file containing the soil moisture data.
      sub_reg (str, optional): The name of the sub-region to filter the data by.
                              Defaults to None (no filtering).

  Returns:
      sklearn.ensemble.RandomForestRegressor: The trained RandomForestRegressor model.
  """
  from sklearn.ensemble import RandomForestRegressor
  from sklearn.model_selection import GridSearchCV


  X_train, _, y_train, _ = data_preprocess_soil(data_path, sub_reg=sub_reg)

  model_soil=RandomForestRegressor(random_state=0)
  model_soil.fit(X_train, y_train)


  joblib.dump(model_soil, f"soil_{sub_reg}.pkl", compress=8)

  return model_soil




def predict_precip(model_path, data_path, sub_reg, metrics=False):


  """
  Evaluates a pre-trained XGBoost model's performance on precipitation prediction.

  Loads a saved XGBoost model, predicts on test data for a specified LGA, and
  calculates performance metrics, including Mean Absolute Error (MAE),
  Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-squared Score (R²),
  and Mean Absolute Percentage Error (MAPE).

  Args:
      model_path (str): Path to the saved XGBoost model file.
      data_path (str): Path to the historical weather data CSV file.
      lga (str): The Local Government Area (LGA) for prediction.

  Returns:
      tuple (np.ndarray, pd.Series):
          - Predicted precipitation values (y_pred).
          - Actual precipitation values (y_test).
  """

  # Load pre_trained model
  model = xgb.XGBRegressor()
  with open(model_path, 'rb') as f:
    model = joblib.load(f)

  # split data
  _, X_test, _, y_test = data_preprocess_precip(data_path, sub_reg=sub_reg)

  # Make prediction
  y_pred = model.predict(X_test)

  if metrics:
    # Calculate metrics
    mae_norm = mean_absolute_error(y_test, y_pred)
    mse_norm = mean_squared_error(y_test, y_pred)
    rmse_norm = np.sqrt(mse_norm)
    r2_norm = r2_score(y_test, y_pred)
    mape_norm = mean_absolute_percentage_error(y_test, y_pred)*100

    print(f"Mean Absolute Error (MAE): {mae_norm:.2f}")
    print(f"Mean Squared Error (MSE): {mse_norm:.2f}")
    print(f"Root Mean Squared Error (RMSE): {rmse_norm:.2f}")
    print(f"R-squared Score (R²): {r2_norm:.2f}")
    print(f"Mean Absolute Percentage Error (MAPE): {mape_norm:.2f}%")
  else:
    pass

  return y_pred, y_test




def predict_soil(model_path, data_path, sub_reg, metrics=False):

  from sklearn.ensemble import RandomForestRegressor

  X_train, X_test, y_train, y_test = data_preprocess_soil(data_path=data_path, sub_reg=sub_reg)

  # Load pre_trained model
  model_soil = RandomForestRegressor()
  with open("random_forest_compressed.pkl", 'rb') as f:
    model_soil = joblib.load(f)

  # Make prediction
  y_pred = model_soil.predict(X_test)

  if metrics:
    # Calculate metrics
    mae_norm = mean_absolute_error(y_test, y_pred)
    mse_norm = mean_squared_error(y_test, y_pred)
    rmse_norm = np.sqrt(mse_norm)
    r2_norm = r2_score(y_test, y_pred)
    mape_norm = mean_absolute_percentage_error(y_test, y_pred)

    print(f"Mean Absolute Error (MAE): {mae_norm:.2f}")
    print(f"Mean Squared Error (MSE): {mse_norm:.2f}")
    print(f"Root Mean Squared Error (RMSE): {rmse_norm:.2f}")
    print(f"R-squared Score (R²): {r2_norm:.2f}")
    print(f"Mean Absolute Percentage Error (MAPE): {mape_norm:.2f}%")
  else:
    pass


  return y_pred, y_test



class MakeAForcast:
  def __init__(self, data_path):
    self.data_path = data_path

  # Define a function to categorize soil moisture based on 'Profile_Soil_Moisture' values
  def soil_label(self, x):
    if x['Soil_pred'] < 0.3:
      return 0
    elif 0.3 <= x['Soil_pred'] <= 0.6:
      return 1
    elif (0.6 <= x['Soil_pred'] <= 0.8):
      return 2
    elif 0.8 < x['Soil_pred'] > 0.9:
      return 3
    else:
      return 4

  # Define a function to categorize precipitation
  def precip_label(self, x):
    if x['Precip_pred (mm/day)'] == 0.0 and (x['precip_D14'] - x['Precip_pred (mm/day)']) == 0.0:
      return 0
    elif x['Precip_pred (mm/day)'] >= 1.0 and (x['precip_D14'] - x['Precip_pred (mm/day)']) >= 25.0:
      return 1
    elif (x['precip_D14'] - x['Precip_pred (mm/day)']) < 25.0:
      return 2

  # Define a function to show precipitation trend
  def trend_label(self, x):
    if (x['precip_vd14'] - x['Precip_pred (mm/day)']) > (x['Precip_pred (mm/day)']):
      return 1
    elif (x['precip_vd14'] - x['Precip_pred (mm/day)']) < (x['Precip_pred (mm/day)']):
      return 0
    else:
      return 2

  def make_future_prediction(self, model_soil_path=None,
                           model_precip_path=None,
                           sub_reg='N_Kano',
                           Q_start_date='2025-01-01',
                           Q_end_date='2025-06-01', return_pred=False):

    """Generates future predictions for soil moisture and precipitation, and interprets them for farming advice.

    This function loads pre-trained models for soil moisture and precipitation,
    uses them to predict future values based on historical data, and then
    categorizes these predictions into farmer-friendly labels.

    Args:
        model_soil_path (str, optional): Path to the saved soil moisture model file. Defaults to None.
        model_precip_path (str, optional): Path to the saved precipitation model file. Defaults to None.
        data_path (str, optional): Path to the historical weather data CSV file. Defaults to None.
        sub_reg (str, optional): The sub-region for prediction. Defaults to 'N_Kano'.
        Q_start_date (str, optional): The start date for the prediction query (YYYY-MM-DD). Defaults to '2025-01-01'.
        Q_end_date (str, optional): The end date for the prediction query (YYYY-MM-DD). Defaults to '2025-06-01'.
        return_pred (bool, optional): Whether to return the detailed prediction dataframe. Defaults to False.

    Returns:
        list or tuple:
            - If `return_pred` is False: A list of dictionaries containing the interpreted predictions for soil moisture,
              precipitation trend, and precipitation season for the specified `Q_end_date`.
            - If `return_pred` is True: A tuple containing the list of dictionaries (as above) and the detailed
              prediction dataframe.
    """
    import warnings
    warnings.filterwarnings('ignore')
    # Load in Data
    df = pd.read_csv(self.data_path, index_col='date', parse_dates=True)
    df = df[df['SUB_REGION'] == sub_reg]
    df_precip = df.iloc[:, [4, 0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11]]
    df_soil = df.iloc[:, [0, 1, 2, 6, 7, 5, 8, 4, 11]]

    # date feature engineering
    date_select = (df.index - pd.Timedelta("365 days"))
    date_select = list(date_select.strftime('%Y-%m-%d'))
    old_ft_soil = df_soil.iloc[:, :-1]
    old_ft_precip = df_precip.iloc[:, 1:]
    train_soil = old_ft_soil.loc[date_select[-1]:]
    train_precip = old_ft_precip.loc[date_select[-1]:]

    train_soil_dict = train_soil.to_dict()
    train_precip_dict = train_precip.to_dict()


    dater2 = (df.index + pd.Timedelta("365 days"))
    dater2 = list(dater2.strftime('%Y-%m-%d'))

    # Make and populate future date
    future_date = pd.date_range(df.index.max(), dater2[-1], freq='D')

    f_df_soil = pd.DataFrame.from_dict(train_soil_dict)
    f_df_precip = pd.DataFrame.from_dict(train_precip_dict)

    f_df_soil.index = future_date
    f_df_precip.index = future_date

    # load model
    # precip_model_path = Path(model_precip_path)
    # list_path = list(precip_model_path.iterdir())
    # for model_path in list_path:
    #   if model_path.stem == 'prec_'+sub_reg:
    #     model = xgb.XGBRegressor()
    #     model.load_model(model_path)
    model = xgb.XGBRegressor()
    with open(model_precip_path, 'rb') as f:
      model = joblib.load(f)

    # Make prediction
    precip_preds = model.predict(f_df_precip)

    # soil_model_path = Path(model_soil_path)
    # list_path_soil = list(soil_model_path.iterdir())
    # for model_soil_path in list_path_soil:
    #   if model_soil_path.stem == 'soil'+sub_reg:
    model_soil = RandomForestRegressor()
    with open(model_soil_path, 'rb') as f:
      model_soil = joblib.load(f)

    # Make prediction
    soil_preds = model_soil.predict(f_df_soil)

    f_df_soil['Precip_pred (mm/day)'] = precip_preds
    pred_df = f_df_soil[['Precip_pred (mm/day)']]
    pred_df['Soil_pred'] = soil_preds

    # filter result base on user preference
    # dater3 = list(future_df.index + pd.Timedelta(f"{duration} days"))
    # result = future_df.loc[f_start_date:dater3[-1]]

    # 14days sum of rainfall
    pred_df['precip_D14'] = int()
    for i in range(0, len(pred_df)):
      if i < (len(pred_df) - 14):
        pred_df['precip_D14'][i] = pred_df['Precip_pred (mm/day)'].iloc[i:i+14].sum()
      if i >= (len(pred_df) - 14):
        pred_df['precip_D14'][i] = pred_df['Precip_pred (mm/day)'].iloc[-14:].sum()

    # rainfall value after 14days
    pred_df['precip_vd14'] = int()
    for i in range(0, len(pred_df)):
      if i < (len(pred_df) - 14):
        pred_df['precip_vd14'][i] = pred_df['Precip_pred (mm/day)'].iloc[i+14]
      if i >= (len(pred_df) - 14):
        pred_df['precip_vd14'][i] = pred_df['Precip_pred (mm/day)'].iloc[-14]

  # Define dictionaries to map numerical values to descriptive labels for soil moisture, precipitation, and rainfall trend
    soil_labels = {
        0: 'Not enough for planting',
        1: 'supports Millet and transitional stage for Cowpea',
        2: 'Sufficient for Maize and other crops, but needs upward in rainfall',
        3: 'Risk of waterlogging',
        4: 'undecided'
    }

    precip_labels = {
        0: 'Dry spell',
        1: 'Raining Season',
        2: 'showers showing the possible start of rainfall',
    }

    Trend_labels = {
        0: 'downward trend in rainfall',
        1: 'upward trend in rainfall',
        2: 'flat no visible change'
    }

  # Feature engineering for Farner's interpretations

    pred_df['precip_labels'] = pred_df.apply(self.precip_label, axis=1)
    pred_df['trend_labels'] = pred_df.apply(self.trend_label, axis=1)
    pred_df['soil_labels'] = pred_df.apply(self.soil_label, axis=1)

    # result to farner's Querry
    querry_result = pred_df.loc[Q_end_date]
    code = [querry_result['precip_labels'], querry_result['trend_labels'], querry_result['soil_labels']]
    result = [{"soil": soil_labels[code[2]]}, {"precipitation_trend": Trend_labels[code[1]]}, {"precipitation_season": precip_labels[code[0]]}]

    if return_pred:
      return result, pred_df
    else:
      return result









